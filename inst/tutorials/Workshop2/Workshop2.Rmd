---
title: "Denoising empirical covariances"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
knitr::opts_chunk$set(echo = FALSE)
```


```{r excercise setup, include=FALSE}
library(learnr)
tutorial_options(exercise.timelimit = 60)
library(PortfolioAnalytics)
library(matlab)
library(corrplot)
library(tidyverse)
library(fontawesome)
library(RColorBrewer)
library(skimr)
tutorial_options(exercise.eval = TRUE)
```

## Introduction

In finance, empirical covariance matrices are often numerically ill-conditioned, as a result of small number of independent observations used to estimate a large number of parameters.  Working with those matrices directly, without treatment, is not recommended.

Even if the covariance matrix is nonsingular
![What is a singular matrice?](https://youtu.be/UqyN7-tRS00){width="50%" align="center"}
, and therefore invertible, the small determinant all but guarantees that the estimations error will be greatly magnified by the inversion process.

The **practical implication** is that these estimation errors cause mis-allocation of assets and substantial transaction costs due to unnecessary rebalancing.  Furthermore, denoising the matrix $\bf{XX^{'}}$ before inverting it should help reduce the variance of regression estimates, and improve the power of statistical tests of hypothesis.  For the same reason, covariance matrices derived from regressed factors (also known as factor-based covariance matrices) also require denoising, and should not be used without numerical treatment.  

### Before we begin
* Login to your RStudio on [Q-RaP](https://q-rap.qub.ac.uk:8787) with the credential provided by the lecturer
* If you don't want to use this instance use your local machine RStudio IDE but **it is your responsibility to keep it up-to-date**. For local set see this set-up workshop [here](https://q-rap.qub.ac.uk/set-up/)

* **Engage your Yoda growth mindset**

![](https://l.imgt.es/resource-preview-imgs/436d1438-0fa0-419f-b0fa-5923410ec22f%2Fyodagmmeme.crop_414x311_50%2C1.preview.jpg){width="30%"}


### Outline

In this workshop you can learn:

* First time set-up of git on Q-RaP RStudio 
* Creating fake portfolio data
* Examine correlations of the fake portfolio data
* Creating a function in R
* Setting up functions in R to *denoise* data using the Marcenko-Pastur distribution

### Tools you will use

* Queen' Management School Remote Analytics Desktop 
1. [Q-RaP RStudio](https://q-rap.qub.ac.uk:8787) Or your local RStudio IDE
2. [Q-RaP RStudio Connect](https://q-rap.qub.ac.uk) 

I have preloaded the packages for this tutorial with 

```{r eval = FALSE}
library(tidyverse) # loads dplyr, ggplot2, and others
library(PortfolioAnalytics)
library(matlab)
library(fontawesome)
library(corrplot)
library(RColorBrewer)
library(skimr)
load("dow30data.RData")
source("marcenko_pastur_fns.R") # pre-defined function to estimate marcenko-pastur probability densities
```


## Exercise 1: Git integration{data-progressive=TRUE}

### First time set-up for git

* Register for account on GitHub (https://github.com/). We recommend using a username that incorporates your name (barryquinn1,ckelly66)

* If you haven't already click on this invite https://classroom.github.com/a/GCR_J0yx to clone the repository for workshop 1.

* If this has been successful you should now have something like this when you visit your GitHub account.

<img src="img/github_success.png" width="30%">

### Create RStudio project using Git

* Log in to [Q-RaP RStudio](https://q-rap.qub.ac.uk:8787) and begin to create a new project using a git repository

![Use this video for guidance on the above set-up](https://vimeo.com/511197952){width="50%"}

* If it is your first time using git you need to run the following in the `Terminal` console, then repeat step 4

```{bash, eval=FALSE}
git config --global user.email "<your github email>"
# This is the email you used to register with GitHub.
git config --global user.name "<your github username>"
```

## Excercise 2: Simulating fake data{data-progressive=TRUE}
In quantitative finance we do not have a laboratory where we can securely experiment in an environment that is controlled.  Most financial research is carried out on *Real* or **Big World** data which is complex, misbehaves and are uncontrollable.  Experimentation in finance is achieved by simulating **Small World** data with know statistical properties which can be controlled.

Portfolio data from the **Big World** is usually insufficient to produce meaningful results, this insufficiency can be illustrated but create some **Small World** random data.  

### Fake portfolio data

The follow creates a portfolio in independently and identically distributed *fake* stock returns. Click `Run Code` to see a fake portfolio created:

```{r fake1, exercise = TRUE}
stocks=20
trading_days=40
fake_port <- array(
  rnorm(trading_days*stocks,
        mean = 0.01,sd = 0.01),
  dim = c(trading_days,stocks)) %>% 
  as.tibble()
fake_port %>% skim()
```
> Describe the data?
**The data is a sample of individual and identically distributed stock returns for 20 stocks over 40 trading days. The sample is drawn from a random normal distribution with mean 0.01 and standard deviation 0.01.  This is the assumed data generating process of daily stock returns that the analyst has postulated.

### Test your knowledge

```{r random, echo=FALSE}
question("what do you expect the correlation matrix of these portfolio to look like if the are drawn to be independent and identically distributed ?",
  answer("I expect there to be no pairwise correlation as the data is random"),
  answer("I expect there to be some real pairwise correlation as the data is random"),
  answer("I expect there to be some spurious pairwise correlation as the data is random", correct = TRUE),
  answer("I expect there to boe some real pairwise correlation as the data is nonrandom")
  ,allow_retry = TRUE
)
```
<div id="random-hint">
**Hint:** use `?rnorm()` in the console to understand the output of this function 
</div>

## Exercise 3: Prettier code with pipes `%>%` {data-progressive=TRUE}
To understand the correct expectation from the above question, lets consider the correlation matrix of our fake portfolio. 

### Pipes 
Firstly, I will introduce the process of piping code in R.  The point of the pipe is to help you write code in a way that is easier to read and understand. To see why the pipe is so useful, weâ€™re going to explore a number of ways of writing the same code.  The pipe operator in R is `%>%` from the `magrittr` pacakge. For more details see [Hadley 2020 "R for Data Science) Chapter 18](https://r4ds.had.co.nz/pipes.html?q=piping#piping-alternatives)

* An algorithm for my morning routine
```{r, eval=FALSE}
leave_home(get_dressed(get_out_of_bed(wake_up(me,time="6:30"),side="left"),trousers=TRUE,shirt=TRUE),car=FALSE,bike=TRUE,pandemic=FALSE)
```

* With piping
```{r, eval=FALSE}
me %>%
  wake_up(time="6:30") %>%
  get_out_of_bed(side="left") %>%
  get_dressed(trousers=TRUE,shirt=TRUE) %>%
  leave_house(car=FALSE,bike=TRUE,pandemic=FALSE)
```

So the piping operator allows the code to be more readable and logic.

### Your turn
```{r pipeit,exercise=TRUE,excerise.eval=FALSE}
## Recode this using piping 
summarise(group_by(mutate(fake_port,Type="Fake"),by="Type"),meanV1=mean(V1))
```

```{r pipeit-solution}
## Recode this using piping 
fake_port %>%
  mutate(Type="Fake") %>%
  group_by(Type) %>%
  summarise(meanV1=mean(V1))
```


## Exercise 4: Pairwise correlation analysis

Given the fake portfolio was created by drawing independent and identically distributed random normal observations, by definition there should be no correlation between the fake stock returns.  

Write some code to evaluate and visualise the correlation of the fake portfolio returns which can be access in the object `fake_port`

```{r cor, exercise=TRUE,exercise.setup="fake1"}

```

```{r cor-solution}
cor(fake_port) %>%
  corrplot(type="upper",
           method = "number",
           order="hclust",
           col=brewer.pal(n=8, name="RdYlBu"))
```

```{r cor-check}
"Fantastic work, you and developing a nice growth mindset."
```

## Excercise 5:  Functions in R {data-progressive=TRUE}

### Create a function in R

R, at its heart, is a functional programming (FP) language. This means that it provides many tools for the creation and manipulation of functions.
```{r add-fn, exercise=TRUE}
# Write a function to add two numbers together then test the function with numbers 1 and 2
add_numbers <- function(a, b) {
  
}
```

```{r add-fn-solution}
# Write a function to add two numbers together
add_numbers <- function(a, b) {
 a + b 
}
add_numbers(1,2)
```

### Create a function in R for marcenko pastur distribution estimates

Recall the Mercenko-Pastur distribution can be defined as:

$$\rho\left(\lambda  \right) = 
    \begin{cases} 
      \frac{T}{N}\frac{\sqrt {\left( {{\lambda _{+}} - \lambda} \right)\left( {\lambda  - {\lambda _{- }}} \right)}}{2\pi \lambda {\sigma ^2}}, & \text{if } \lambda \in [\lambda _{+},\lambda _{-}] \\
      0, & \text{if } \lambda \notin [\lambda _{+},\lambda _{-}]
     \end{cases}$$

where the maximum expected eigenvalue is $\lambda_{+}=\sigma^2(1+\sqrt{N/T})^2$ and the minimum expected eigenvalue is  $\lambda_{-}=\sigma^2(1-\sqrt{N/T})^2$

The following translates the above maths into `R` code. 
```{r mp, exercise = TRUE, exercise.eval=TRUE}
mp_pdf<-function(var,t,m,pts) {
  q=t/m
  eMin<-var*(1-(1./q)^.5)^2 
  eMax<-var*(1+(1./q)^.5)^2 
  eVal<-linspace(eMin,eMax,pts)
  pd<-q/(2*pi*var*eVal)*((eMax-eVal)*(eVal-eMin))^.5
  pdf<-tibble(pd=pd,e=eVal) 
  return(pdf)  
}
```

### Running a function

```{r mp1,exercise=TRUE}
#Run the Code and then use the function to create the Marcenko Pastur distribution for the fake portfolio when the variance=1.  

```

```{r mp1-solution}
mp<-mp_pdf(1,trading_days,stocks,stocks)
```


## Excercise 6: Plot the distriubtion

Research how the package `ggplot2` works and then attempt to plot the distribution created earlier.

```{r , include=FALSE}
stocks=20
trading_days=40
fake_port <- array(
  rnorm(trading_days*stocks,
        mean = 0.01,sd = 0.01),
  dim = c(trading_days,stocks)) %>% 
  as.tibble()
mp<-mp_pdf(1,trading_days,stocks,stocks)
```
  

```{r mplot,exercise=TRUE, exercise.setup="mp1-solution"}
# using ggplot to plot the marcenko distribution estimates of the fake portfolio

```

```{r mplot-solution}
# using ggplot to plot the marcenko distribution estimates of the fake portfolio
mp %>% 
  ggplot(aes(x=e,y=pd)) + 
  geom_line()
```
